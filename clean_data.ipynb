{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from nltk import word_tokenize,pos_tag_sents,WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " 'clean_data.csv',\n",
       " 'clean_data.ipynb',\n",
       " 'clean_data_Cldpoly.csv',\n",
       " 'README.md',\n",
       " 'train-balanced.csv',\n",
       " 'train_balanced.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get relative path\n",
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the training data from the csv file\n",
    "header = ['label','comment']\n",
    "data = pd.read_table('train-balanced.csv',\n",
    "                    sep='\\t', \n",
    "                    delimiter=',', \n",
    "                    names=header,\n",
    "                    usecols=[0,1],\n",
    "                    dtype={'label':int,'comment':str},\n",
    "                    keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to clean the comments\n",
    "def comment_clean(user_comment):\n",
    "    #remove the # from hashtag\n",
    "    if '#' in user_comment:\n",
    "        hash_tag = re.search('#',user_comment)\n",
    "        if hash_tag is not None:\n",
    "            user_comment = user_comment.replace(hash_tag.group(0),' ')\n",
    "    #remove the redit tags(r/) from comment\n",
    "    if 'r/' in user_comment:\n",
    "        r_tag = re.search('r/',user_comment)\n",
    "        if r_tag is not None:\n",
    "            user_comment = user_comment.replace(r_tag.group(0),' ')\n",
    "    #remove the URL links from comments  \n",
    "    if 'HTTP' in user_comment:\n",
    "        # url of the form [link name](http://url)\n",
    "        url_link = re.search('\\[(.*)\\(HTTP(.*)\\)', user_comment)\n",
    "        if url_link is not None:\n",
    "            user_comment = user_comment.replace(url_link.group(0),' ')\n",
    "    if 'http' in user_comment:\n",
    "        # url of the form [link name](http://url)\n",
    "        url_link = re.search('\\[(.*)\\(http(.*)\\)', user_comment)\n",
    "        if url_link is not None:\n",
    "            user_comment = user_comment.replace(url_link.group(0),' ')\n",
    "        else:\n",
    "            #url of the form http:/\n",
    "            url_link = re.search('http(.*)', user_comment)\n",
    "            if url_link is not None:\n",
    "                user_comment = user_comment.replace(url_link.group(0),' ')                \n",
    "    return user_comment           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010783"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean each comment\n",
    "data['comment'] = data.comment.apply(comment_clean)\n",
    "# remove data with empty comments\n",
    "valid_comment = data['comment'] != ' '\n",
    "data = data[valid_comment]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken  541.9575788974762\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "txt = data['comment'].tolist()\n",
    "#POS tagging for all the tokens in the sentence\n",
    "tagged_texts = pos_tag_sents(map(word_tokenize, txt))\n",
    "end_time = time.time()\n",
    "data['POS'] = tagged_texts\n",
    "print(\"time taken \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to collect number of interjection\n",
    "def comment_interjection(user_comment):\n",
    "    count = Counter(tag for word,tag in user_comment)\n",
    "    return count['UH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##feature extraction\n",
    "# number of interjection\n",
    "data['interjection']  = data.POS.apply(comment_interjection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the cleaned data into a csv file\n",
    "data.to_csv('clean_data.csv',\n",
    "           sep= '|',\n",
    "           index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Script used for project presentation demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stwkn\\Anaconda3\\envs\\py36\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n",
      "C:\\Users\\stwkn\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time \n",
    "import ast\n",
    "from nltk import word_tokenize,pos_tag_sents,WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from nltk.corpus import wordnet\n",
    "from textblob import TextBlob\n",
    "import constants\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SIA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stwkn\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\base.py:311: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\stwkn\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\base.py:311: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.20.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Load the saved model and predict the output\n",
    "from sklearn.externals import joblib\n",
    "loaded_model = joblib.load('RF_oldfeatures.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the test data from the csv file\n",
    "## Demo_rf.csv and Demo_CNN.csv files contains 10 rows for clean_test_balanced file which are picked randomly ,\n",
    "# and gives 70% accuracy on saved models.\n",
    "\n",
    "test_data_RF = pd.read_table('Demo_rf.csv',\n",
    "                    sep='|', \n",
    "                    usecols=[0,1,2],\n",
    "                    keep_default_na=False)\n",
    "\n",
    "test_data_CNN = pd.read_table('Demo_CNN.csv',\n",
    "                    sep='|', \n",
    "                    usecols=[0,1,2],\n",
    "                    keep_default_na=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I used to hold my tek-dek against the window</td>\n",
       "      <td>Skateboard for me. Honestly didn't realize so ...</td>\n",
       "      <td>[(I, PRP), (used, VBD), (to, TO), (hold, VB), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>They tried to email Matt Daemon, but it bounce...</td>\n",
       "      <td>Or maybe even that they found Matt Damon.</td>\n",
       "      <td>[(They, PRP), (tried, VBD), (to, TO), (email, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, 43% winrate as ADC and 39% winrate as mi...</td>\n",
       "      <td>Let's take a moment and appreciate how balance...</td>\n",
       "      <td>[(Yeah, UH), (,, ,), (43, CD), (%, NN), (winra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bro, Bitcoin is the currency of the future!</td>\n",
       "      <td>I take my money in currency please.</td>\n",
       "      <td>[(Bro, NNP), (,, ,), (Bitcoin, NNP), (is, VBZ)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>You're Northernlion's alt account aren't you?</td>\n",
       "      <td>Broken stopwatch idea This may or may not have...</td>\n",
       "      <td>[(You, PRP), ('re, VBP), (Northernlion, NNP), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Here's a little secret on how to make LOTS AND...</td>\n",
       "      <td>You can pay people money with Facebook. I have...</td>\n",
       "      <td>[(Here, RB), ('s, VBZ), (a, DT), (little, JJ),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>The police did a great job, they saved the ban...</td>\n",
       "      <td>California police killed hostage in July bank ...</td>\n",
       "      <td>[(The, DT), (police, NN), (did, VBD), (a, DT),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>There's a difference between believing in God'...</td>\n",
       "      <td>We can be welcoming, and we should. Hospitalit...</td>\n",
       "      <td>[(There, EX), ('s, VBZ), (a, DT), (difference,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Finally!</td>\n",
       "      <td>4K Video camera finally packed in a phone</td>\n",
       "      <td>[(Finally, RB), (!, .)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>I'll have to make a note to ask her about how ...</td>\n",
       "      <td>Who wants to be the person to ask her about th...</td>\n",
       "      <td>[(I, PRP), ('ll, MD), (have, VB), (to, TO), (m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0       I used to hold my tek-dek against the window   \n",
       "1      0  They tried to email Matt Daemon, but it bounce...   \n",
       "2      1  Yeah, 43% winrate as ADC and 39% winrate as mi...   \n",
       "3      1        Bro, Bitcoin is the currency of the future!   \n",
       "4      1      You're Northernlion's alt account aren't you?   \n",
       "5      1  Here's a little secret on how to make LOTS AND...   \n",
       "6      1  The police did a great job, they saved the ban...   \n",
       "7      0  There's a difference between believing in God'...   \n",
       "8      1                                           Finally!   \n",
       "9      1  I'll have to make a note to ask her about how ...   \n",
       "\n",
       "                                      parent_comment  \\\n",
       "0  Skateboard for me. Honestly didn't realize so ...   \n",
       "1          Or maybe even that they found Matt Damon.   \n",
       "2  Let's take a moment and appreciate how balance...   \n",
       "3                I take my money in currency please.   \n",
       "4  Broken stopwatch idea This may or may not have...   \n",
       "5  You can pay people money with Facebook. I have...   \n",
       "6  California police killed hostage in July bank ...   \n",
       "7  We can be welcoming, and we should. Hospitalit...   \n",
       "8          4K Video camera finally packed in a phone   \n",
       "9  Who wants to be the person to ask her about th...   \n",
       "\n",
       "                                                 POS  \n",
       "0  [(I, PRP), (used, VBD), (to, TO), (hold, VB), ...  \n",
       "1  [(They, PRP), (tried, VBD), (to, TO), (email, ...  \n",
       "2  [(Yeah, UH), (,, ,), (43, CD), (%, NN), (winra...  \n",
       "3  [(Bro, NNP), (,, ,), (Bitcoin, NNP), (is, VBZ)...  \n",
       "4  [(You, PRP), ('re, VBP), (Northernlion, NNP), ...  \n",
       "5  [(Here, RB), ('s, VBZ), (a, DT), (little, JJ),...  \n",
       "6  [(The, DT), (police, NN), (did, VBD), (a, DT),...  \n",
       "7  [(There, EX), ('s, VBZ), (a, DT), (difference,...  \n",
       "8                            [(Finally, RB), (!, .)]  \n",
       "9  [(I, PRP), ('ll, MD), (have, VB), (to, TO), (m...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test label= 0, Predicted= 1\n",
      "Test label= 0, Predicted= 0\n",
      "Test label= 1, Predicted= 1\n",
      "Test label= 1, Predicted= 1\n",
      "Test label= 1, Predicted= 0\n",
      "Test label= 1, Predicted= 1\n",
      "Test label= 1, Predicted= 1\n",
      "Test label= 0, Predicted= 0\n",
      "Test label= 1, Predicted= 1\n",
      "Test label= 1, Predicted= 0\n",
      "\n",
      "With Random Forest Accuracy is  70.0\n"
     ]
    }
   ],
   "source": [
    "## Random Forest Model\n",
    "\n",
    "# Reads the emoticon look up table file\n",
    "header = ['EmoticonSymbol','SentimentScore']\n",
    "emoticon_data = pd.read_csv('EmoticonLookupTable.txt', delimiter='\\t', encoding = 'ISO-8859-1',names=header)\n",
    "\n",
    "#Writing emoticons to a dictionary\n",
    "emoji_dict = emoticon_data.groupby('EmoticonSymbol')['SentimentScore'].apply(list).to_dict()\n",
    "\n",
    "# Reading the slang dictionary that is already created\n",
    "f = open(\"Slangdictionary.txt\",\"r\")\n",
    "res1=f.read()\n",
    "f.close()\n",
    "slangdict = ast.literal_eval(res1)\n",
    "\n",
    "#get POS tags\n",
    "text = test_data_RF['comment']\n",
    "pos_tagged_texts = pos_tag_sents(map(word_tokenize, text))\n",
    "test_data_RF[\"POS\"] = pos_tagged_texts\n",
    "\n",
    "## function to get positive word count \n",
    "def get_pos_neg_word_count(tokens):     \n",
    "    pos_word_count = 0\n",
    "    neg_word_count = 0    \n",
    "    pos_flag = False\n",
    "    neg_flag = False\n",
    "    flip_count = 0        \n",
    "    for word in tokens:\n",
    "        senti = sia.polarity_scores(str(word)) \n",
    "        if senti[\"pos\"] == 1:\n",
    "            pos_word_count += 1\n",
    "            pos_flag = True\n",
    "            if neg_flag:\n",
    "                flip_count += 1\n",
    "                neg_flag =  False                \n",
    "        elif senti[\"neg\"] == 1:\n",
    "            neg_word_count += 1\n",
    "            neg_flag = True\n",
    "            if pos_flag:\n",
    "                flip_count +=1\n",
    "                pos_flag = False\n",
    "    return pos_word_count, neg_word_count,flip_count\n",
    "\n",
    "\n",
    "## function to get list of emojis in a comment\n",
    "def find_emoji(text):\n",
    "    return list(x for x in text.split() if x in emoji_dict.keys() )\n",
    "  \n",
    "#helper function to collect number of interjection\n",
    "def comment_interjection(user_comment):\n",
    "    count = Counter(tag for word,tag in user_comment)\n",
    "    return count['UH']    \n",
    "\n",
    "#get heighly emotional words (associated with POS tags)\n",
    "def get_high_emotion_words(postags):\n",
    "    highly_pos = 0\n",
    "    highly_neg = 0\n",
    "    POS_list = ['JJ','JJR','JJS', 'RB','RBR','RBS','VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "    num_tokens = len(postags)\n",
    "    for i in range(num_tokens):\n",
    "        if postags[i][1] in POS_list:            \n",
    "            #check sentiment of next word\n",
    "            if i < (num_tokens - 1) :\n",
    "                senti_word = sia.polarity_scores(postags[i+1][0])\n",
    "                if senti_word['pos'] == 1:\n",
    "                    highly_pos += 1\n",
    "                if senti_word['neg'] == 1:\n",
    "                    highly_neg += 1                \n",
    "    return highly_pos, highly_neg        \n",
    "    \n",
    "# get the parent sentiment\n",
    "def get_parent_sentiment(comment):\n",
    "    sentiments = TextBlob(str(comment)).sentiment\n",
    "    polarity = sentiments.polarity\n",
    "    if polarity >= 0.1:\n",
    "        return 1\n",
    "    elif polarity < -0.1:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0        \n",
    "\n",
    "# Concatinate the extracted features\n",
    "def featureextraction(dataframe, field, func, column_names):\n",
    "    return pd.concat((\n",
    "        dataframe,\n",
    "        dataframe[field].apply(\n",
    "            lambda cell: pd.Series(func(cell), index=column_names))), axis=1)\n",
    "\n",
    "\n",
    "# Extracting the features for each comment \n",
    "# Punctuation Features and presence of sarcastic symbol\n",
    "def allfeatures(user_comment):\n",
    "    if '!' or '.' or '?' in user_comment:\n",
    "        Numofexclaimations = user_comment.count('!')\n",
    "        Numofdots = user_comment.count('.')\n",
    "        Numofquestionmarks = user_comment.count('?')\n",
    "    else:\n",
    "        Numofexclaimations = 0\n",
    "        Numofdots = 0\n",
    "        Numofquestionmarks = 0\n",
    "    if '(!)' in user_comment:\n",
    "        SarcasticSymbol = 1\n",
    "    else:\n",
    "        SarcasticSymbol = 0\n",
    "    sentiments = TextBlob(str(user_comment)).sentiment\n",
    "    polarity = sentiments.polarity\n",
    "    subjectivity = sentiments.subjectivity\n",
    "    numofcapitals = sum(x.isupper() for x in user_comment.split() if len(x) > 1 )\n",
    "    elist = find_emoji(user_comment)\n",
    "    pscore =0\n",
    "    nscore = 0\n",
    "    for item in elist:\n",
    "        if (emoji_dict[item][0] == 1):\n",
    "            pscore += 1\n",
    "        elif (emoji_dict[item][0] == -1):\n",
    "            nscore += 1\n",
    "    \n",
    "            \n",
    "    return Numofexclaimations,Numofdots,Numofquestionmarks,SarcasticSymbol,polarity,subjectivity,numofcapitals,pscore,nscore\n",
    "                \n",
    "input_features = featureextraction(test_data_RF, 'comment', allfeatures, ['Numofexclaimations', 'Numofdots','Numofquestionmarks','SarcasticSymbol','Polarity', 'Subjectivity','NumofCapitalWords','PositiveEmojiCount','NegativeEmojiCount'])\n",
    "input_features['interjection']  = test_data_RF.POS.apply(comment_interjection)\n",
    "                                   \n",
    "# Create a list of the feature column's names\n",
    "features = ['Numofexclaimations','Numofdots', 'Numofquestionmarks', 'SarcasticSymbol', 'Polarity','Subjectivity', 'NumofCapitalWords', 'PositiveEmojiCount','NegativeEmojiCount','interjection',]\n",
    "\n",
    "X_test = input_features[features]\n",
    "y_test = input_features['label']\n",
    "                                   \n",
    "y_predict = loaded_model.predict(X_test)\n",
    "result = loaded_model.score(input_features[features], input_features['label'])\n",
    "num_comments = len(input_features['comment'])\n",
    "for i in range(num_comments):\n",
    "    print(\"Test label= %s, Predicted= %s\" % (input_features['label'].iloc[i], y_predict[i]))\n",
    "    \n",
    "print(\"\\nWith Random Forest Accuracy is \", result*100)                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I used to hold my tek-dek against the window</td>\n",
       "      <td>Skateboard for me. Honestly didn't realize so ...</td>\n",
       "      <td>[(I, PRP), (used, VBD), (to, TO), (hold, VB), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>They tried to email Matt Daemon, but it bounce...</td>\n",
       "      <td>Or maybe even that they found Matt Damon.</td>\n",
       "      <td>[(They, PRP), (tried, VBD), (to, TO), (email, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, 43% winrate as ADC and 39% winrate as mi...</td>\n",
       "      <td>Let's take a moment and appreciate how balance...</td>\n",
       "      <td>[(Yeah, UH), (,, ,), (43, CD), (%, NN), (winra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bro, Bitcoin is the currency of the future!</td>\n",
       "      <td>I take my money in currency please.</td>\n",
       "      <td>[(Bro, NNP), (,, ,), (Bitcoin, NNP), (is, VBZ)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>You're Northernlion's alt account aren't you?</td>\n",
       "      <td>Broken stopwatch idea This may or may not have...</td>\n",
       "      <td>[(You, PRP), ('re, VBP), (Northernlion, NNP), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Here's a little secret on how to make LOTS AND...</td>\n",
       "      <td>You can pay people money with Facebook. I have...</td>\n",
       "      <td>[(Here, RB), ('s, VBZ), (a, DT), (little, JJ),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>The police did a great job, they saved the ban...</td>\n",
       "      <td>California police killed hostage in July bank ...</td>\n",
       "      <td>[(The, DT), (police, NN), (did, VBD), (a, DT),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>There's a difference between believing in God'...</td>\n",
       "      <td>We can be welcoming, and we should. Hospitalit...</td>\n",
       "      <td>[(There, EX), ('s, VBZ), (a, DT), (difference,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Finally!</td>\n",
       "      <td>4K Video camera finally packed in a phone</td>\n",
       "      <td>[(Finally, RB), (!, .)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>I'll have to make a note to ask her about how ...</td>\n",
       "      <td>Who wants to be the person to ask her about th...</td>\n",
       "      <td>[(I, PRP), ('ll, MD), (have, VB), (to, TO), (m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0       I used to hold my tek-dek against the window   \n",
       "1      0  They tried to email Matt Daemon, but it bounce...   \n",
       "2      1  Yeah, 43% winrate as ADC and 39% winrate as mi...   \n",
       "3      1        Bro, Bitcoin is the currency of the future!   \n",
       "4      1      You're Northernlion's alt account aren't you?   \n",
       "5      1  Here's a little secret on how to make LOTS AND...   \n",
       "6      1  The police did a great job, they saved the ban...   \n",
       "7      0  There's a difference between believing in God'...   \n",
       "8      1                                           Finally!   \n",
       "9      1  I'll have to make a note to ask her about how ...   \n",
       "\n",
       "                                      parent_comment  \\\n",
       "0  Skateboard for me. Honestly didn't realize so ...   \n",
       "1          Or maybe even that they found Matt Damon.   \n",
       "2  Let's take a moment and appreciate how balance...   \n",
       "3                I take my money in currency please.   \n",
       "4  Broken stopwatch idea This may or may not have...   \n",
       "5  You can pay people money with Facebook. I have...   \n",
       "6  California police killed hostage in July bank ...   \n",
       "7  We can be welcoming, and we should. Hospitalit...   \n",
       "8          4K Video camera finally packed in a phone   \n",
       "9  Who wants to be the person to ask her about th...   \n",
       "\n",
       "                                                 POS  \n",
       "0  [(I, PRP), (used, VBD), (to, TO), (hold, VB), ...  \n",
       "1  [(They, PRP), (tried, VBD), (to, TO), (email, ...  \n",
       "2  [(Yeah, UH), (,, ,), (43, CD), (%, NN), (winra...  \n",
       "3  [(Bro, NNP), (,, ,), (Bitcoin, NNP), (is, VBZ)...  \n",
       "4  [(You, PRP), ('re, VBP), (Northernlion, NNP), ...  \n",
       "5  [(Here, RB), ('s, VBZ), (a, DT), (little, JJ),...  \n",
       "6  [(The, DT), (police, NN), (did, VBD), (a, DT),...  \n",
       "7  [(There, EX), ('s, VBZ), (a, DT), (difference,...  \n",
       "8                            [(Finally, RB), (!, .)]  \n",
       "9  [(I, PRP), ('ll, MD), (have, VB), (to, TO), (m...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input label= 0, Predicted= [0]\n",
      "Test input label= 0, Predicted= [0]\n",
      "Test input label= 1, Predicted= [0]\n",
      "Test input label= 0, Predicted= [0]\n",
      "Test input label= 1, Predicted= [0]\n",
      "Test input label= 0, Predicted= [0]\n",
      "Test input label= 0, Predicted= [0]\n",
      "Test input label= 1, Predicted= [1]\n",
      "Test input label= 1, Predicted= [0]\n",
      "Test input label= 1, Predicted= [1]\n",
      "\n",
      "With CNN Accuracy is : 70.0\n"
     ]
    }
   ],
   "source": [
    "## CNN model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import re\n",
    "special_character_removal=re.compile(r'[^a-z\\d ]',re.IGNORECASE)\n",
    "replace_numbers=re.compile(r'\\d+',re.IGNORECASE)\n",
    "\n",
    "def text_to_wordlist(text):   \n",
    "    # Convert words to lower case and split them\n",
    "    text = text.lower().split()    \n",
    "    text = \" \".join(text)    \n",
    "    #Remove Special Characters\n",
    "    text=special_character_removal.sub('',text)     \n",
    "    #Replace Numbers\n",
    "    text=replace_numbers.sub('n',text)  \n",
    "    \n",
    "    return(text)\n",
    "\n",
    "X_test = test_data_CNN['comment']\n",
    "test_comments=[]\n",
    "for text in X_test:\n",
    "    test_comments.append(text_to_wordlist(text))\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(test_comments)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_comments)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "test_data = pad_sequences(test_sequences, maxlen=2500, padding='post')\n",
    "\n",
    "\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model_4.json','r')\n",
    "loaded_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_json)\n",
    "loaded_model.load_weights('model_4.h5')\n",
    "loaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "y_predict = loaded_model.predict_classes(test_data)\n",
    "\n",
    "y_test = test_data_CNN['label']\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "num_comments = len(test_data_CNN['comment'])\n",
    "for i in range(num_comments):\n",
    "    print(\"Test input label= %s, Predicted= %s\" % (test_data_CNN['label'].iloc[i], y_predict[i]))\n",
    "    \n",
    "print(\"\\nWith CNN Accuracy is :\", accuracy_score(y_test,y_predict) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
